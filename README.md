# TOPSIS Implementation

## Overview
A comprehensive repository demonstrating the implementation of TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) for analyzing an evaluation matrix of text summarization models. This project applies multi-criteria decision-making (MCDM) to rank and compare different summarization models based on multiple performance metrics.

## Key Features
- **TOPSIS-Based Evaluation**: Implements TOPSIS for objective ranking of text summarization models.
- **Metric Preprocessing**: Ensures consistency in ranking by normalizing evaluation metrics.
- **Optimal Ranking Calculation**: Identifies ideal and anti-ideal solutions for precise ranking.
- **Result Visualization**: Generates bar charts, radar plots, and comparative tables for better interpretation.

## Project Overview
In text summarization, models are evaluated based on multiple performance metrics such as ROUGE scores (ROUGE-1, ROUGE-2, ROUGE-L), BLEU, and METEOR. Ranking these models objectively requires a systematic approach like TOPSIS, which follows these steps:

1. **Normalization**: Standardizes the evaluation matrix.
2. **Weighting Criteria**: Assigns importance to each metric.
3. **Ideal & Anti-Ideal Solutions**: Determines best and worst possible outcomes.
4. **Similarity Score Calculation**: Ranks models based on proximity to the ideal solution.

## Visualization
The results are presented using:
- **Bar Charts**: For clear ranking visualization.
- **Radar Plots**: To compare multiple models across metrics.
- **Comparative Tables**: Displaying numerical ranking results.

This repository is a valuable resource for researchers and developers in text summarization, model evaluation, and decision-making in NLP. ðŸš€

